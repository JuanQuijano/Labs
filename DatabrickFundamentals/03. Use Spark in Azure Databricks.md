# Use Spark in Azure Databricks #
Azure Databricks is a Microsoft Azure-based version of the popular open-source Databricks platform. Azure Databricks is built on Apache Spark, and offers a highly scalable solution for data engineering and analysis tasks that involve working with data in files. One of the benefits of Spark is support for a wide range of programming languages, including Java, Scala, Python, and SQL; making Spark a very flexible solution for data processing workloads including data cleansing and manipulation, statistical analysis and machine learning, and data analytics and visualization.

## Task 1: Explore data using a notebook ##
As in many Spark environments, Databricks supports the use of notebooks to combine notes and interactive code cells that you can use to explore data.

In the Azure Databricks workspace portal for your workspace, in the sidebar on the left, select Workspace. Then select the ⌂ Home folder.

At the top of the page, in the ⋮ menu next to your user name, select Import. Then in the Import dialog box, select URL and import the notebook from https://github.com/MicrosoftLearning/dp-203-azure-data-engineer/raw/master/Allfiles/labs/24/Databricks-Spark.ipynb

Connect the notebook to your cluster, and follow the instructions it contains; running the cells it contains to explore data in files.

    It is very important that you read all the instructions and explanations of what you are going to do.